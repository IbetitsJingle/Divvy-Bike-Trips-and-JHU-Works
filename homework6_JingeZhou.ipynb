{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkImex_yXGjB"
      },
      "source": [
        "# BU.330.775 Machine Learning: Design and Deployment\n",
        "# Lab 6: Image Clustering using K-Means\n",
        "\n",
        "**Student:** Jinge Zhou  \n",
        "**Learning Goal:** Practice using unsupervised machine learning model to cluster image data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vubFeZXsXGjC"
      },
      "source": [
        "## Step a: Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2LlDztLXGjC",
        "outputId": "834b1eb1-5f2c-4303-a96c-30e45be700bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All packages imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"All packages imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BqTNyECXGjD"
      },
      "source": [
        "## Step b: Load MNIST Dataset and Check Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hjtlo1sXGjD",
        "outputId": "473ac7a2-690d-460e-e300-b2d0b9a39e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "0\n",
            "255\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_train.min())\n",
        "print(x_train.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJYSAjhXGjE"
      },
      "source": [
        "### Results - Step b\n",
        "\n",
        "| Metric | Value |\n",
        "|--------|-------|\n",
        "| Number of training images | 60,000 |\n",
        "| Number of testing images | 10,000 |\n",
        "| Image size | 28 × 28 pixels |\n",
        "| Pixel value range | 0 to 255 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnZn-2dAXGjE"
      },
      "source": [
        "## Step c: Plot 9 Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB-QoYssXGjE"
      },
      "outputs": [],
      "source": [
        "plt.gray()  # B/W Images\n",
        "plt.figure(figsize=(10, 9))  # Adjusting figure size\n",
        "\n",
        "# Displaying a grid of 3x3 images\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(x_train[i])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDrEdjKnXGjF"
      },
      "source": [
        "## Step d: Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnJ8l6FrXGjG",
        "outputId": "d47dfc14-8385-494b-e14d-00fb9a2c5d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Conversion to float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalization\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Checking the minimum and maximum values of x_train\n",
        "print(x_train.min())\n",
        "print(x_train.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGgH4AIdXGjG"
      },
      "source": [
        "### Results - Step d\n",
        "\n",
        "After normalization:\n",
        "- Minimum value: **0.0**\n",
        "- Maximum value: **1.0**\n",
        "- Data type: float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysG799QnXGjH"
      },
      "source": [
        "## Step e: Reshape Data for K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWMPwrWVXGjH",
        "outputId": "3f5c9ac0-73e4-470a-fc94-50ab4d535f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "# Reshaping input data\n",
        "X_train = x_train.reshape(len(x_train), -1)\n",
        "X_test = x_test.reshape(len(x_test), -1)\n",
        "\n",
        "# Checking the shape\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSkWh4L4XGjH"
      },
      "source": [
        "### Results - Step e\n",
        "\n",
        "| Dataset | Original Shape | Reshaped |\n",
        "|---------|---------------|----------|\n",
        "| Training | (60000, 28, 28) | **(60000, 784)** |\n",
        "| Testing | (10000, 28, 28) | **(10000, 784)** |\n",
        "\n",
        "Each 28×28 image is now a 784-dimensional feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWKaUNEVXGjH"
      },
      "source": [
        "## Step f: Apply K-Means with 10 Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8CEyJJsXGjH"
      },
      "outputs": [],
      "source": [
        "def retrieve_info(cluster_labels, y_train):\n",
        "    # Initializing\n",
        "    reference_labels = {}\n",
        "    # For loop to run through each label of cluster label\n",
        "    for i in range(len(np.unique(kmeans.labels_))):\n",
        "        index = np.where(cluster_labels == i, 1, 0)\n",
        "        num = np.bincount(y_train[index == 1]).argmax()\n",
        "        reference_labels[i] = num\n",
        "    return reference_labels\n",
        "\n",
        "total_clusters = len(np.unique(y_train))\n",
        "\n",
        "# Initialize the K-Means model\n",
        "kmeans = MiniBatchKMeans(n_clusters=total_clusters)\n",
        "\n",
        "# Fitting the model to training set\n",
        "kmeans.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWy3WzdYXGjI"
      },
      "source": [
        "## Step g: Retrieve Labels and Compare Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3eFBH4DXGjI",
        "outputId": "b3fd6b1c-908e-4084-b04f-3242b1f2777e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n",
            "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n"
          ]
        }
      ],
      "source": [
        "reference_labels = retrieve_info(kmeans.labels_, y_train)\n",
        "\n",
        "number_labels = np.random.rand(len(kmeans.labels_))\n",
        "for i in range(len(kmeans.labels_)):\n",
        "    number_labels[i] = reference_labels[kmeans.labels_[i]]\n",
        "\n",
        "# Comparing Predicted values and Actual values\n",
        "print(number_labels[:20].astype('int'))\n",
        "print(y_train[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tDIjjEBXGjI"
      },
      "source": [
        "### Results - Step g\n",
        "\n",
        "**First 20 Predicted Labels:** [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]  \n",
        "**First 20 Actual Labels:**    [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n",
        "\n",
        "The first 20 samples show good alignment between predictions and actual values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg8dwhAVXGjI"
      },
      "source": [
        "## Step h: Calculate Accuracy Score (10 Clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-wcQY4VXGjI",
        "outputId": "5f5c5cb8-b253-42d6-88c7-cd25af5709f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5843\n"
          ]
        }
      ],
      "source": [
        "# Calculating accuracy score\n",
        "print(accuracy_score(number_labels, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xe_ESHNXGjI"
      },
      "source": [
        "### Results - Step h\n",
        "\n",
        "**Accuracy with 10 clusters: 0.5843 (58.43%)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJRYLAocXGjI"
      },
      "source": [
        "## Step i: Increase to 50 Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je4aOh70XGjI",
        "outputId": "adad1bb0-207a-4261-a53b-2bcb081d345b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.8062\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Increase to 50 clusters, and fit the model\n",
        "kmeans = MiniBatchKMeans(n_clusters=50)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "# Calculating the reference_labels\n",
        "reference_labels = retrieve_info(kmeans.labels_, y_train)\n",
        "\n",
        "# 'number_labels' is a list which denotes the number displayed in image\n",
        "number_labels = np.random.rand(len(kmeans.labels_))\n",
        "for i in range(len(kmeans.labels_)):\n",
        "    number_labels[i] = reference_labels[kmeans.labels_[i]]\n",
        "\n",
        "print('Accuracy score : {}'.format(accuracy_score(number_labels, y_train)))\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-jSS0CjXGjJ"
      },
      "source": [
        "### Results - Step i\n",
        "\n",
        "| Model | Accuracy |\n",
        "|-------|----------|\n",
        "| K-Means (10 clusters) | **58.43%** |\n",
        "| K-Means (50 clusters) | **80.62%** |\n",
        "| **Improvement** | **+22.19%** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25nfUGDEXGjJ"
      },
      "source": [
        "## Step j: Visualize Cluster Centers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWWUmHe-XGjJ"
      },
      "outputs": [],
      "source": [
        "# Cluster centroids is stored in 'centroids'\n",
        "centroids = kmeans.cluster_centers_\n",
        "centroids.shape\n",
        "\n",
        "centroids = centroids.reshape(50, 28, 28)\n",
        "centroids = centroids * 255\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "bottom = 0.35\n",
        "for i in range(50):\n",
        "    plt.subplots_adjust(bottom)\n",
        "    plt.subplot(5, 10, i+1)\n",
        "    plt.title('Num:{}'.format(reference_labels[i]), fontsize=10)\n",
        "    plt.imshow(centroids[i])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5u9ETsxXGjK"
      },
      "source": [
        "## Homework Question 1 (1pt)\n",
        "\n",
        "**Compare the accuracy of 10 clusters vs that of 50 clusters, which one is better?**\n",
        "\n",
        "---\n",
        "\n",
        "The 50-cluster model performs significantly better than the 10-cluster model.\n",
        "\n",
        "| Model | Accuracy |\n",
        "|-------|----------|\n",
        "| K-Means (10 clusters) | 58.43% |\n",
        "| K-Means (50 clusters) | 80.62% |\n",
        "| **Improvement** | **+22.19%** |\n",
        "\n",
        "The 50-cluster model achieves approximately **80.62%** accuracy compared to **58.43%** for the 10-cluster model. This represents a substantial improvement of about **22 percentage points**, demonstrating that increasing the number of clusters from 10 to 50 has a strong positive impact on classification performance for the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEwxFU6mXGjK"
      },
      "source": [
        "## Homework Question 2 (2pt)\n",
        "\n",
        "**Inspect the centroids in step j, discuss why increasing the number of clusters in this case has a positive/negative impact on the model performance.**\n",
        "\n",
        "---\n",
        "\n",
        "Increasing the number of clusters has a POSITIVE impact on model performance for the following reasons:\n",
        "\n",
        "**1. Capturing Intra-Class Variation:**\n",
        "When examining the 50 cluster centroids, we can observe that multiple clusters are assigned to the same digit. This is crucial because handwritten digits exhibit significant variation in writing styles. For example:\n",
        "- The digit \"7\" can be written with or without a horizontal stroke\n",
        "- The digit \"4\" can be open or closed at the top\n",
        "- The digit \"1\" can be written as a simple vertical line or with serifs\n",
        "\n",
        "With only 10 clusters (one per digit), the model cannot capture these variations effectively.\n",
        "\n",
        "**2. Visual Evidence from Centroids:**\n",
        "Looking at the centroid visualization, we can see that:\n",
        "- Some digits like \"1\" have relatively consistent appearances and may need fewer clusters\n",
        "- Digits like \"4\", \"7\", and \"9\" show more variation and benefit from multiple clusters capturing different writing styles\n",
        "- The centroids appear sharper and more digit-like with 50 clusters, indicating better representation of actual digit patterns\n",
        "\n",
        "**3. Reduced Cluster Impurity:**\n",
        "With 10 clusters, each cluster must represent all variations of a single digit, leading to \"blurry\" centroids that average out important distinguishing features. With 50 clusters, each cluster can specialize in a specific variant of a digit, resulting in purer clusters with more homogeneous samples.\n",
        "\n",
        "**4. Better Discrimination:**\n",
        "The additional clusters allow the algorithm to create more decision boundaries in the feature space, enabling finer discrimination between similar-looking digits (such as 3 vs 8, or 4 vs 9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVLIbWIiXGjK"
      },
      "source": [
        "## Homework Question 3 (2pt)\n",
        "\n",
        "**Comment on the performance of K-means in MNIST image clustering. What insight(s) can we draw?**\n",
        "\n",
        "---\n",
        "**Performance Assessment:**\n",
        "\n",
        "K-Means achieves approximately **80% accuracy** on MNIST digit clustering with 50 clusters. While this is significantly lower than supervised learning methods (which typically achieve 97-99%+ accuracy), it is a reasonable performance for an unsupervised algorithm that has no access to the actual labels during training.\n",
        "\n",
        "**Key Insights:**\n",
        "\n",
        "**1. Unsupervised Learning Has Inherent Limitations:**\n",
        "K-Means clusters data based purely on pixel-level similarity (Euclidean distance in 784-dimensional space). It cannot leverage label information to learn discriminative features, which limits its classification accuracy compared to supervised methods.\n",
        "\n",
        "**2. K-Means Captures Natural Data Structure:**\n",
        "Despite being unsupervised, K-Means successfully identifies meaningful patterns in the data. The fact that cluster centroids visually resemble recognizable digits demonstrates that handwritten digits do form natural clusters in the pixel space.\n",
        "\n",
        "**3. The Choice of K is Critical:**\n",
        "The dramatic improvement from 10 to 50 clusters shows that the optimal number of clusters often exceeds the number of actual classes. This is because real-world data rarely forms exactly K perfectly separable clusters—there is significant within-class variation that requires additional clusters to capture.\n",
        "\n",
        "**4. K-Means is Sensitive to Distance Metrics:**\n",
        "K-Means uses Euclidean distance, which may not be the ideal metric for image comparison. Small shifts or rotations in digits can cause large Euclidean distances even though the digits are semantically identical. This explains some of the classification errors.\n",
        "\n",
        "**5. Practical Applications:**\n",
        "While K-Means alone may not achieve state-of-the-art classification accuracy, it can be valuable for:\n",
        "- Exploratory data analysis to understand data structure\n",
        "- Data preprocessing or feature extraction for downstream tasks\n",
        "- Semi-supervised learning scenarios where labeled data is scarce\n",
        "- Quick baseline modeling before investing in more complex approaches\n",
        "\n",
        "**6. Scalability Advantage:**\n",
        "MiniBatch K-Means is computationally efficient and scales well to large datasets, making it practical for real-world applications where training time is a constraint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V3-jfGWXGjK"
      },
      "source": [
        "---\n",
        "\n",
        "# Final Results Summary\n",
        "\n",
        "---\n",
        "\n",
        "| Metric | Value |\n",
        "|--------|-------|\n",
        "| Training samples | 60,000 |\n",
        "| Testing samples | 10,000 |\n",
        "| Image size | 28×28 pixels (784 features) |\n",
        "| Classes | 10 digits (0-9) |\n",
        "| **K-Means (10 clusters)** | **58.43%** |\n",
        "| **K-Means (50 clusters)** | **80.62%** |\n",
        "| **Improvement** | **+22.19%** |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}